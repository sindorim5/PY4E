\r\n\r\n 과 \n\n의 차이??

ord(): ASCII 문자에 대응하는 숫자를 리턴

크롤링(crawling): 웹페이지를 그대로 가져와서 데이터를 추출하는 행위.

파싱(parsing): 구문분석. 데이터를 분해, 분석하여 원하는 형태로 조립하고 다시 빼내는 프로그램.
정보를 원하는 대로 가공하여 서버에서 불러들이는 것을 의미한다.

BeautifulSoup: 파이썬으로 웹을 크롤링 한 후
HTML 태그로 부터 원하는 데이터를 가져올 때, 파싱하기 편하게 해주는 라이브러리

앵커태그: 웹문서가 너무 길 경우 필요한 곳에, 문서안에 이름을 붙여 놓고
그 위치로 한번에 이동하는 링크를 anchor라 하며 <a> 태그로 표시한다.

href: hypertext reference

Exercise 12.1: Change the socket program socket1.py to prompt the user
for the URL so it can read any web page. You can use split('/') to
break the URL into its component parts so you can extract the host
name for the socket connect call. Add error checking using try and
except to handle the condition where the user enters an improperly
formatted or non-existent URL.

Exercise 12.2: Change your socket program so that it counts the number
of characters it has received and stops displaying any text after it has
shown 3000 characters. The program should retrieve the entire docu-
ment and count the total number of characters and display the count
of the number of characters at the end of the document.

Exercise 12.3: Use urllib to replicate the previous exercise of (1) retrieving
the document from a URL, (2) displaying up to 3000 characters, and
(3) counting the overall number of characters in the document. Don’t
worry about the headers for this exercise, simply show the first 3000
characters of the document contents.

Exercise 12.4: Change the urllinks.py program to extract and count para-
graph (p) tags from the retrieved HTML document and display the
count of the paragraphs as the output of your program. Do not display
the paragraph text, only count them. Test your program on several
small web pages as well as some larger web pages.

Exercise 12.5: (Advanced) Change the socket program so that it only shows
data after the headers and a blank line have been received. Remember
that recv receives characters (newlines and all), not lines.
